{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1920</td>\n",
       "      <td>At last the Federal Reserve Board has issued r...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1920</td>\n",
       "      <td>WILL TEST DOOR SERVICE.</td>\n",
       "      <td>Service Board to Further Examine I.R.T. Safety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1920</td>\n",
       "      <td>Sanction for Chinese Contracts.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1920</td>\n",
       "      <td>LEADS FRAZIER BY 4,496.</td>\n",
       "      <td>Langer's Margin Falls in North Dakota--Gronna ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>CHICAGO, April 30.--With 300 suspicious charac...</td>\n",
       "      <td>Federal Agents and Police Round-- up Suspiciou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                              title  \\\n",
       "0  1920  At last the Federal Reserve Board has issued r...   \n",
       "1  1920                            WILL TEST DOOR SERVICE.   \n",
       "2  1920                    Sanction for Chinese Contracts.   \n",
       "3  1920                            LEADS FRAZIER BY 4,496.   \n",
       "4  1920  CHICAGO, April 30.--With 300 suspicious charac...   \n",
       "\n",
       "                                             excerpt  \n",
       "0                                                     \n",
       "1  Service Board to Further Examine I.R.T. Safety...  \n",
       "2                                                     \n",
       "3  Langer's Margin Falls in North Dakota--Gronna ...  \n",
       "4  Federal Agents and Police Round-- up Suspiciou...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"nyt_data.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_str_length(df, column_key, max_len=1):\n",
    "    #returns a new df that satisfies the condition df[column_key] has a str of len > max_len\n",
    "    return df[df[column_key].str.len() > max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function adapted for single rows\n",
    "def tokenize_function(row):\n",
    "    result = tokenizer(row[\"title\"].str + row['excerpt'].str, truncation=True, max_length=512)\n",
    "    if tokenizer.is_fast:\n",
    "        # Extract word IDs only for the single input\n",
    "        result[\"word_ids\"] = result.word_ids()\n",
    "    return result\n",
    "\n",
    "# Apply tokenization to each subset\n",
    "a = df[df[\"year\"] < 1960]\n",
    "a[\"tokenized\"] = a.apply(\n",
    "    lambda row: tokenize_function(row), axis=1\n",
    ")\n",
    "\n",
    "b = df[(df[\"year\"] >= 1960) & (df[\"year\"] < 1990)]\n",
    "b[\"tokenized\"] = b.apply(\n",
    "    lambda row: tokenize_function(row), axis=1\n",
    ")\n",
    "\n",
    "c = df[df[\"year\"] >= 1990]\n",
    "c[\"tokenized\"] = c.apply(\n",
    "    lambda row: tokenize_function(row), axis=1\n",
    ")\n",
    "\n",
    "# Drop unused columns after tokenization, to reduce memory usage\n",
    "a = a.drop(columns=[\"title\", \"excerpt\", \"combined\"])\n",
    "b = b.drop(columns=[\"title\", \"excerpt\", \"combined\"])\n",
    "c = c.drop(columns=[\"title\", \"excerpt\", \"combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_train \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#b_train = b.sample(n=2000, random_state=42)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#c_train = c.sample(n=2000, random_state=42) \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mlen\u001b[39m(a_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a_train = a.sample(n=2000, random_state=42)\n",
    "#b_train = b.sample(n=2000, random_state=42)\n",
    "#c_train = c.sample(n=2000, random_state=42) \n",
    "\n",
    "len(a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "text = \"  Hello, how are YOU?  \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
